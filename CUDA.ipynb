{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"CUDA.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5TKZWQhLZ80u","executionInfo":{"status":"ok","timestamp":1610147100133,"user_tz":180,"elapsed":5572,"user":{"displayName":"Daniel Lamounier Heringer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMpl5NEQA6GuSGv0pgZtVBHfVsuoXxPDxY8rWzZA=s64","userId":"02437197682562816450"}},"outputId":"6daf386a-f5e9-4b34-aea7-e6de0f5d533a"},"source":["# importa macro %%cu\n","!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n","\n","# carrega plugin\n","%load_ext nvcc_plugin"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n","  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-1zlycxbb\n","  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-1zlycxbb\n","Building wheels for collected packages: NVCCPlugin\n","  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4308 sha256=0da40964510f46abd7392a74fd30473c896cc454d37880c93bdb31a82ffdf2fd\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-i0qlvqak/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n","Successfully built NVCCPlugin\n","Installing collected packages: NVCCPlugin\n","Successfully installed NVCCPlugin-0.0.2\n","created output directory at /content/src\n","Out bin /content/result.out\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AYsKFrD5Z97G","executionInfo":{"status":"ok","timestamp":1610147101075,"user_tz":180,"elapsed":6509,"user":{"displayName":"Daniel Lamounier Heringer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMpl5NEQA6GuSGv0pgZtVBHfVsuoXxPDxY8rWzZA=s64","userId":"02437197682562816450"}},"outputId":"fe21c153-1667-4b82-e1af-747286c8fa7d"},"source":["%cd /usr/local\n","%cd cuda-10.0\n","%cd samples\n","%cd 1_Utilities\n","%cd deviceQuery\n","!ls\n","!make\n","!./deviceQuery"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local\n","/usr/local/cuda-10.0\n","/usr/local/cuda-10.0/samples\n","/usr/local/cuda-10.0/samples/1_Utilities\n","/usr/local/cuda-10.0/samples/1_Utilities/deviceQuery\n","deviceQuery.cpp  Makefile  NsightEclipse.xml  readme.txt\n","/usr/local/cuda-10.0/bin/nvcc -ccbin g++ -I../../common/inc  -m64    -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_75,code=compute_75 -o deviceQuery.o -c deviceQuery.cpp\n","/usr/local/cuda-10.0/bin/nvcc -ccbin g++   -m64      -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_75,code=compute_75 -o deviceQuery deviceQuery.o \n","mkdir -p ../../bin/x86_64/linux/release\n","cp deviceQuery ../../bin/x86_64/linux/release\n","./deviceQuery Starting...\n","\n"," CUDA Device Query (Runtime API) version (CUDART static linking)\n","\n","Detected 1 CUDA Capable device(s)\n","\n","Device 0: \"Tesla T4\"\n","  CUDA Driver Version / Runtime Version          10.1 / 10.0\n","  CUDA Capability Major/Minor version number:    7.5\n","  Total amount of global memory:                 15080 MBytes (15812263936 bytes)\n","  (40) Multiprocessors, ( 64) CUDA Cores/MP:     2560 CUDA Cores\n","  GPU Max Clock rate:                            1590 MHz (1.59 GHz)\n","  Memory Clock rate:                             5001 Mhz\n","  Memory Bus Width:                              256-bit\n","  L2 Cache Size:                                 4194304 bytes\n","  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\n","  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n","  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n","  Total amount of constant memory:               65536 bytes\n","  Total amount of shared memory per block:       49152 bytes\n","  Total number of registers available per block: 65536\n","  Warp size:                                     32\n","  Maximum number of threads per multiprocessor:  1024\n","  Maximum number of threads per block:           1024\n","  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n","  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n","  Maximum memory pitch:                          2147483647 bytes\n","  Texture alignment:                             512 bytes\n","  Concurrent copy and kernel execution:          Yes with 3 copy engine(s)\n","  Run time limit on kernels:                     No\n","  Integrated GPU sharing Host Memory:            No\n","  Support host page-locked memory mapping:       Yes\n","  Alignment requirement for Surfaces:            Yes\n","  Device has ECC support:                        Enabled\n","  Device supports Unified Addressing (UVA):      Yes\n","  Device supports Compute Preemption:            Yes\n","  Supports Cooperative Kernel Launch:            Yes\n","  Supports MultiDevice Co-op Kernel Launch:      Yes\n","  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 4\n","  Compute Mode:\n","     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n","\n","deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.1, CUDA Runtime Version = 10.0, NumDevs = 1\n","Result = PASS\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pO7FNYg42iUY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610550713113,"user_tz":180,"elapsed":854,"user":{"displayName":"Daniel Lamounier Heringer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMpl5NEQA6GuSGv0pgZtVBHfVsuoXxPDxY8rWzZA=s64","userId":"02437197682562816450"}},"outputId":"f53b8e19-cf23-4f3e-ca6d-df438137effa"},"source":["# %%cu\r\n","%%writefile id.cu\r\n","#include <stdio.h>\r\n","#include <stdlib.h>\r\n","#include <math.h>\r\n","#include <unistd.h>\r\n","#include <assert.h>\r\n","#include <sys/time.h>\r\n","\r\n","//Função para calcular MDC\r\n","__device__ int gcd(int u, int v) {\r\n","\tif (v == 0)\r\n","\t\treturn u;\r\n","\treturn gcd(v, u % v);\r\n","}\r\n","\r\n","__global__ void soma_divisores(long int*g_sequencia, long int *g_num, long int *g_den, int tam){\r\n","    int pos,sum, factor, done,n;\r\n","\r\n","    //Pega a posição do vetor que aquela thread irá trabalhar\r\n","    pos = (blockIdx.x*blockDim.x)+threadIdx.x;\r\n","\r\n","    //Verifica se está em uma posição válida, uma vez que o último bloco\r\n","    //pode ter threads restantes, ou seja, o posição pode exceder o número de elementos\r\n","    if(pos<tam){\r\n","        \r\n","        //Já soma o próprio elemento e 1, pois são divisores\r\n","        sum = 1 + g_sequencia[pos];\r\n","        done = g_sequencia[pos];\r\n","        factor = 2;\r\n","\r\n","        while (factor < (done/2)+1) {  // faz a soma dos elementos divisiveis por i\r\n","          if ((g_sequencia[pos] % factor) == 0) {\r\n","            sum += (factor);\r\n","          }\r\n","          factor++;\r\n","        }\r\n","        g_num[pos] = sum; \r\n","        g_den[pos] = g_sequencia[pos]; \r\n","        //Faz o MDC pra encontrar o numerador e o denominador\r\n","        n = gcd(g_num[pos], g_den[pos]); \r\n","        g_num[pos] /= n; //numerador\r\n","        g_den[pos] /= n; //denominador\r\n","        \r\n","    }\r\n","        \r\n","}\r\n","\r\n","int main(int argc, char **argv) {\r\n","\tlong int start;\r\n","\tlong int end,n;\r\n","  int i, count,j;\r\n","\tstruct timeval inic,fim;\r\n","\r\n","\twhile (1) {\r\n","\t\tscanf(\"%ld %ld\", &start, &end);\r\n","\t\tif (start == 0 && end == 0)\r\n","\t\t\tbreak;\r\n","    \r\n","\t  gettimeofday(&inic,0);\r\n","\r\n","    //calcula a quantidade de elementos\r\n","    long int last = end - start + 1;\r\n","\t\tprintf(\"Number %ld to %ld\\n\", start, end);\r\n","    \r\n","    //aloca um vetor no device e outro no host para armazenar todos os elementos\r\n","    long int *sequencia, *g_sequencia;\r\n","    sequencia = (long int*) malloc(sizeof(long int) * last);\r\n","    cudaMalloc(&g_sequencia, sizeof(long int)*last);\r\n","\r\n","    //Inicializa o vetor de sequencias\r\n","    for (i = start,count = 0; i <= end; i++,count++) {\r\n","        sequencia[count] = i;\r\n","    }\r\n","\r\n","    //copia as sequencias do host pra GPU\r\n","    cudaMemcpy(g_sequencia, sequencia, sizeof(long int)*last, cudaMemcpyHostToDevice);\r\n","   \r\n","    //aloca o vetor de numerador na GPU e host\r\n","    long int *num, *g_num;\r\n","    num = (long int*) malloc(sizeof(long int) * last);\r\n","    cudaMalloc(&g_num, sizeof(long int)*last);\r\n","\r\n","    //aloca o vetor de denominador na GPU e host\r\n","    long int *den, *g_den;\r\n","    den = (long int*) malloc(sizeof(long int) * last);\r\n","    cudaMalloc(&g_den, sizeof(long int)*last);\r\n","\r\n","    int threadsPerBlock;\r\n","    //se o número de elementos for menor que 1024, define \r\n","    //apenas 1 bloco com a quantidade de threads igual a de elementos\r\n","    if(last<32){\r\n","        n=1;\r\n","        threadsPerBlock = last;\r\n","    //Se não, verifica o número de blocos que será necessário\r\n","    }else{\r\n","        n = last/32;\r\n","        if(last%32 != 0){ // Caso o número de blocos não seja divisível por 1024\r\n","          n+=1;             //adiciona-se mais um bloco, que recebará a última parte\r\n","        }                   //menor que 1024 \r\n","        threadsPerBlock = 32;\r\n","    }\r\n","    \r\n","    int dimGrid = n;\r\n","\r\n","    //chama o kernel\r\n","    soma_divisores<<<dimGrid, threadsPerBlock>>>(g_sequencia, g_num, g_den, last);\r\n","\r\n","    //Função para o Host aguardar a execução de todas as threads\r\n","    cudaDeviceSynchronize();\r\n","    \r\n","    //copia os vetores de numerador e denomiador da GPU pro host\r\n","    cudaMemcpy(num, g_num, sizeof(long int)*last, cudaMemcpyDeviceToHost);\r\n","    cudaMemcpy(den, g_den, sizeof(long int)*last, cudaMemcpyDeviceToHost);\r\n","\r\n","  int count=0;\r\n","    //percorre todos elementos comparando-os com todos os outros\r\n","    //se o númerador e o denominador são iguais, são mutualmente amigáveis\r\n","    for (i = 0; i < last; i++) {\r\n","      for (j = i + 1; j < last; j++) {\r\n","        if ((num[i] == num[j]) && (den[i] == den[j]))\r\n","          count++;\r\n","          //printf(\"%ld and %ld are FRIENDLY\\n\", sequencia[i], sequencia[j]);\r\n","      }\r\n","    }\r\n","    printf(\"%d\\n\", count);\r\n","\t  gettimeofday(&fim,0);\r\n","    printf(\"\\nElapsed time:%f sec\\n\", (fim.tv_sec+fim.tv_usec/1000000.) - (inic.tv_sec+inic.tv_usec/1000000.));\r\n","    \r\n","    free(sequencia);\r\n","    free(num);\r\n","    free(den);\r\n","\r\n","    //Libera a memória alocada na GPU e a reseta\r\n","    cudaFree(g_sequencia);\r\n","    cudaFree(g_num);\r\n","    cudaFree(g_den);\r\n","    cudaDeviceReset();\r\n","    \r\n","\t}\r\n","\r\n","\treturn EXIT_SUCCESS;\r\n","}\r\n"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Overwriting id.cu\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6FYP0lI63zJZ","executionInfo":{"status":"ok","timestamp":1610550736451,"user_tz":180,"elapsed":8888,"user":{"displayName":"Daniel Lamounier Heringer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMpl5NEQA6GuSGv0pgZtVBHfVsuoXxPDxY8rWzZA=s64","userId":"02437197682562816450"}},"outputId":"c01c3f3d-e9a0-4c2f-959c-f2919f58c9b7"},"source":["!nvcc id.cu -o id && ./id "],"execution_count":22,"outputs":[{"output_type":"stream","text":["1 15000\n","Number 1 to 15000\n","293\n","\n","Elapsed time:0.377938 sec\n","^C\n"],"name":"stdout"}]}]}